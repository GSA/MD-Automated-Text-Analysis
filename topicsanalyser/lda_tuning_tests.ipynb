{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = TopicsFinder(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha = [0.01]\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta = [0.01]\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "corpus = finder.corpus\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    # cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                    #                               k=k, a=a, b=b)\n",
    "                    mod, cv = finder.fit_model(\n",
    "                        random_state=100,\n",
    "                        chunksize=chunksize,\n",
    "                        passes=passes,\n",
    "                        iterations=iterations,\n",
    "                        eval_every=eval_every,\n",
    "                        num_topics = k,\n",
    "                        alpha = a,\n",
    "                        eta = b,\n",
    "\n",
    "                    )\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv.get_coherence())\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "data_filename = './sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx'\n",
    "reader = TextFileReader(data_filename)\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "# reader = TextFileReader('./sample_data/data.xlsx')\n",
    "# data = reader.get_dataframe('Please briefly describe an example of one burdensome administrative task or process which you believe is \"low value\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.2629155731641215\n"
    }
   ],
   "source": [
    "# benchmark model (no tuning)\n",
    "finder = TopicsFinder(data)\n",
    "_, cv = finder.fit_model(\n",
    "    random_state=100,\n",
    "    num_topics = 5,\n",
    ")\n",
    "\n",
    "score = cv.get_coherence()\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWhenTrialKeepBeingPrunedCallback:\n",
    "    def __init__(self, threshold: int):\n",
    "        self.threshold = threshold\n",
    "        self._consequtive_pruned_count = 0\n",
    "\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        if trial.state == optuna.trial.TrialState.PRUNED:\n",
    "            self._consequtive_pruned_count += 1\n",
    "        else:\n",
    "            self._consequtive_pruned_count = 0\n",
    "\n",
    "        if self._consequtive_pruned_count >= self.threshold:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    k = trial.suggest_int('num_topics', 1, 10)\n",
    "    a = trial.suggest_categorical('alpha', list(np.arange(0.01, 1, 0.3)) + ['symmetric','asymmetric'])\n",
    "    b = trial.suggest_categorical('eta', list(np.arange(0.01, 1, 0.3)) + ['symmetric'])\n",
    "    # a = 'auto'\n",
    "    # b = 'auto'\n",
    "    chunksize = trial.suggest_int('chunksize', 100, 2000, step=100)\n",
    "    passes = trial.suggest_int('passes', 1, 10, step=2)\n",
    "    iterations = trial.suggest_int('iterations', 50, 500, step=50)\n",
    "    eval_every = None  \n",
    "\n",
    "    finder = TopicsFinder(data)\n",
    "    _, cv = finder.fit_model(\n",
    "        random_state=100,\n",
    "        chunksize=chunksize,\n",
    "        passes=passes,\n",
    "        iterations=iterations,\n",
    "        eval_every=eval_every,\n",
    "        num_topics = k,\n",
    "        alpha = a,\n",
    "        eta = b,\n",
    "    )\n",
    "    score = cv.get_coherence()\n",
    "\n",
    "    trial.report(score, 0)\n",
    "    # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\u001b[32m[I 2021-02-16 13:49:27,775]\u001b[0m A new study created in memory with name: CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1-study\u001b[0m\n\u001b[32m[I 2021-02-16 13:49:47,627]\u001b[0m Trial 0 finished with value: 0.18226465441974926 and parameters: {'num_topics': 2, 'alpha': 'asymmetric', 'eta': 'symmetric', 'chunksize': 2000, 'passes': 5, 'iterations': 400}. Best is trial 0 with value: 0.18226465441974926.\u001b[0m\n\u001b[32m[I 2021-02-16 13:50:08,005]\u001b[0m Trial 1 finished with value: 0.1967406014838316 and parameters: {'num_topics': 2, 'alpha': 0.31, 'eta': 0.31, 'chunksize': 200, 'passes': 9, 'iterations': 350}. Best is trial 1 with value: 0.1967406014838316.\u001b[0m\n\u001b[32m[I 2021-02-16 13:50:22,137]\u001b[0m Trial 2 finished with value: 0.27918251021239665 and parameters: {'num_topics': 7, 'alpha': 0.01, 'eta': 0.31, 'chunksize': 400, 'passes': 1, 'iterations': 150}. Best is trial 2 with value: 0.27918251021239665.\u001b[0m\n\u001b[32m[I 2021-02-16 13:50:35,130]\u001b[0m Trial 3 finished with value: 0.09983229660904934 and parameters: {'num_topics': 1, 'alpha': 'symmetric', 'eta': 0.9099999999999999, 'chunksize': 700, 'passes': 1, 'iterations': 150}. Best is trial 2 with value: 0.27918251021239665.\u001b[0m\n\u001b[32m[I 2021-02-16 13:50:55,037]\u001b[0m Trial 4 finished with value: 0.3663025311681231 and parameters: {'num_topics': 9, 'alpha': 0.01, 'eta': 0.61, 'chunksize': 1500, 'passes': 5, 'iterations': 500}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:51:11,499]\u001b[0m Trial 5 finished with value: 0.2854620185308204 and parameters: {'num_topics': 6, 'alpha': 0.61, 'eta': 0.01, 'chunksize': 1200, 'passes': 3, 'iterations': 50}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:51:33,081]\u001b[0m Trial 6 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 13:51:50,515]\u001b[0m Trial 7 finished with value: 0.2677947247233128 and parameters: {'num_topics': 3, 'alpha': 0.31, 'eta': 0.31, 'chunksize': 1600, 'passes': 3, 'iterations': 100}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:52:04,747]\u001b[0m Trial 8 finished with value: 0.29589638049386713 and parameters: {'num_topics': 10, 'alpha': 'symmetric', 'eta': 'symmetric', 'chunksize': 1300, 'passes': 1, 'iterations': 500}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:52:20,656]\u001b[0m Trial 9 finished with value: 0.29593056412141067 and parameters: {'num_topics': 9, 'alpha': 0.01, 'eta': 'symmetric', 'chunksize': 300, 'passes': 3, 'iterations': 350}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:52:41,300]\u001b[0m Trial 10 finished with value: 0.30706103383525096 and parameters: {'num_topics': 8, 'alpha': 0.9099999999999999, 'eta': 0.61, 'chunksize': 1600, 'passes': 7, 'iterations': 500}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:53:01,576]\u001b[0m Trial 11 finished with value: 0.30706103383525096 and parameters: {'num_topics': 8, 'alpha': 0.9099999999999999, 'eta': 0.61, 'chunksize': 1600, 'passes': 7, 'iterations': 500}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:53:21,924]\u001b[0m Trial 12 finished with value: 0.3234234369104064 and parameters: {'num_topics': 10, 'alpha': 0.9099999999999999, 'eta': 0.61, 'chunksize': 1600, 'passes': 7, 'iterations': 500}. Best is trial 4 with value: 0.3663025311681231.\u001b[0m\n\u001b[32m[I 2021-02-16 13:53:45,089]\u001b[0m Trial 13 finished with value: 0.3954010516348504 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.61, 'chunksize': 900, 'passes': 9, 'iterations': 250}. Best is trial 13 with value: 0.3954010516348504.\u001b[0m\n\u001b[32m[I 2021-02-16 13:54:07,841]\u001b[0m Trial 14 finished with value: 0.3377294738984421 and parameters: {'num_topics': 5, 'alpha': 0.01, 'eta': 0.61, 'chunksize': 800, 'passes': 9, 'iterations': 250}. Best is trial 13 with value: 0.3954010516348504.\u001b[0m\n\u001b[32m[I 2021-02-16 13:54:26,871]\u001b[0m Trial 15 finished with value: 0.4294871795190215 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 900, 'passes': 5, 'iterations': 250}. Best is trial 15 with value: 0.4294871795190215.\u001b[0m\n\u001b[32m[I 2021-02-16 13:54:50,174]\u001b[0m Trial 16 finished with value: 0.4234781703278821 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 900, 'passes': 9, 'iterations': 250}. Best is trial 15 with value: 0.4294871795190215.\u001b[0m\n\u001b[32m[I 2021-02-16 13:55:09,100]\u001b[0m Trial 17 finished with value: 0.335968656618233 and parameters: {'num_topics': 5, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 700, 'passes': 5, 'iterations': 200}. Best is trial 15 with value: 0.4294871795190215.\u001b[0m\n\u001b[32m[I 2021-02-16 13:55:32,077]\u001b[0m Trial 18 finished with value: 0.5159024164759427 and parameters: {'num_topics': 9, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 1100, 'passes': 9, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:55:48,872]\u001b[0m Trial 19 finished with value: 0.48279394732609104 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 3, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:56:05,334]\u001b[0m Trial 20 finished with value: 0.4870982393289876 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 3, 'iterations': 350}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:56:21,645]\u001b[0m Trial 21 finished with value: 0.4549208928038061 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 400, 'passes': 3, 'iterations': 350}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:56:38,335]\u001b[0m Trial 22 finished with value: 0.48279394732609104 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 3, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:56:55,026]\u001b[0m Trial 23 finished with value: 0.405163457288946 and parameters: {'num_topics': 6, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 100, 'passes': 3, 'iterations': 400}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:57:10,138]\u001b[0m Trial 24 finished with value: 0.4320822898942519 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 1100, 'passes': 1, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:57:26,295]\u001b[0m Trial 25 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 13:57:45,574]\u001b[0m Trial 26 finished with value: 0.448123434299764 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 1300, 'passes': 5, 'iterations': 450}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:57:59,902]\u001b[0m Trial 27 finished with value: 0.3482048410038641 and parameters: {'num_topics': 4, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 100, 'passes': 1, 'iterations': 200}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:58:17,177]\u001b[0m Trial 28 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 13:58:34,642]\u001b[0m Trial 29 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 13:58:53,950]\u001b[0m Trial 30 finished with value: 0.4225112280269028 and parameters: {'num_topics': 6, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 1100, 'passes': 5, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:59:10,554]\u001b[0m Trial 31 finished with value: 0.48279394732609104 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 3, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:59:27,077]\u001b[0m Trial 32 finished with value: 0.4539891329559187 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 300, 'passes': 3, 'iterations': 350}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:59:41,398]\u001b[0m Trial 33 finished with value: 0.4826468661454584 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 1, 'iterations': 200}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 13:59:57,207]\u001b[0m Trial 34 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:00:11,476]\u001b[0m Trial 35 finished with value: 0.49154987783886317 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 700, 'passes': 1, 'iterations': 450}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 14:00:25,562]\u001b[0m Trial 36 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:00:40,008]\u001b[0m Trial 37 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:00:54,017]\u001b[0m Trial 38 finished with value: 0.4765094180927029 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 400, 'passes': 1, 'iterations': 400}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 14:01:09,104]\u001b[0m Trial 39 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:01:28,064]\u001b[0m Trial 40 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:01:44,263]\u001b[0m Trial 41 finished with value: 0.48279394732609104 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 3, 'iterations': 350}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 14:02:00,781]\u001b[0m Trial 42 finished with value: 0.4928287908278253 and parameters: {'num_topics': 9, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 300, 'passes': 3, 'iterations': 300}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 14:02:17,093]\u001b[0m Trial 43 finished with value: 0.4928287908278253 and parameters: {'num_topics': 9, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 300, 'passes': 3, 'iterations': 250}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 14:02:35,850]\u001b[0m Trial 44 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:02:51,928]\u001b[0m Trial 45 finished with value: 0.4928287908278253 and parameters: {'num_topics': 9, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 300, 'passes': 3, 'iterations': 250}. Best is trial 18 with value: 0.5159024164759427.\u001b[0m\n\u001b[32m[I 2021-02-16 14:03:09,415]\u001b[0m Trial 46 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:03:23,352]\u001b[0m Trial 47 pruned. \u001b[0m\n\u001b[32m[I 2021-02-16 14:03:39,745]\u001b[0m Trial 48 pruned. \u001b[0m\n"
    }
   ],
   "source": [
    "import logging\n",
    "import re\n",
    "import ntpath\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.handlers.RotatingFileHandler(\"optuna.log\",maxBytes=100000,backupCount=3))\n",
    "\n",
    "study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(3)\n",
    "# use the input file name as the study name\n",
    "study_name = re.sub(r'[.]\\w+','', ntpath.basename(data_filename)) + \"-study\"\n",
    "# storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "# study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=False)\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name)\n",
    "study.optimize(objective, n_trials=100, callbacks=[study_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(optuna.importance.get_param_importances(study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1613501109224",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}