{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = TopicsFinder(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha = [0.01]\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta = [0.01]\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "corpus = finder.corpus\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    # cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                    #                               k=k, a=a, b=b)\n",
    "                    mod, cv = finder.fit_LDA_model(\n",
    "                        random_state=100,\n",
    "                        chunksize=chunksize,\n",
    "                        passes=passes,\n",
    "                        iterations=iterations,\n",
    "                        eval_every=eval_every,\n",
    "                        num_topics = k,\n",
    "                        alpha = a,\n",
    "                        eta = b,\n",
    "\n",
    "                    )\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv.get_coherence())\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "data_filename = './sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx'\n",
    "reader = TextFileReader(data_filename)\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "# reader = TextFileReader('./sample_data/data.xlsx')\n",
    "# data = reader.get_dataframe('Please briefly describe an example of one burdensome administrative task or process which you believe is \"low value\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWhenTrialKeepBeingPrunedCallback:\n",
    "    def __init__(self, threshold: int):\n",
    "        self.threshold = threshold\n",
    "        self._consequtive_pruned_count = 0\n",
    "\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        if trial.state == optuna.trial.TrialState.PRUNED:\n",
    "            self._consequtive_pruned_count += 1\n",
    "        else:\n",
    "            self._consequtive_pruned_count = 0\n",
    "\n",
    "        if self._consequtive_pruned_count >= self.threshold:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    k = trial.suggest_int('num_topics', 1, 10)\n",
    "    a = trial.suggest_categorical('alpha', list(np.arange(0.01, 1, 0.3)) + ['symmetric','asymmetric'])\n",
    "    b = trial.suggest_categorical('eta', list(np.arange(0.01, 1, 0.3)) + ['symmetric'])\n",
    "    # a = 'auto'\n",
    "    # b = 'auto'\n",
    "    chunksize = trial.suggest_int('chunksize', 100, 2000, step=100)\n",
    "    passes = trial.suggest_int('passes', 1, 10, step=2)\n",
    "    iterations = trial.suggest_int('iterations', 50, 500, step=50)\n",
    "    eval_every = None  \n",
    "\n",
    "    finder = TopicsFinder(data)\n",
    "    _, cv = finder.fit_LDA_model(\n",
    "        random_state=100,\n",
    "        chunksize=chunksize,\n",
    "        passes=passes,\n",
    "        iterations=iterations,\n",
    "        eval_every=eval_every,\n",
    "        num_topics = k,\n",
    "        alpha = a,\n",
    "        eta = b,\n",
    "    )\n",
    "    score = cv.get_coherence()\n",
    "\n",
    "    trial.report(score, 0)\n",
    "    # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\u001b[32m[I 2021-02-09 13:05:21,991]\u001b[0m Using an existing study with name 'CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1-study' instead of creating a new one.\u001b[0m\nCSS_Hiring_Data_FedEmployee_Reason_OTHER_v1-study\n\u001b[32m[I 2021-02-09 13:05:44,423]\u001b[0m Trial 8 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 13:06:00,519]\u001b[0m Trial 9 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 13:06:19,392]\u001b[0m Trial 10 finished with value: 0.36090694558499176 and parameters: {'num_topics': 10, 'alpha': 0.9099999999999999, 'eta': 0.31, 'chunksize': 100, 'passes': 5, 'iterations': 50}. Best is trial 3 with value: 0.39528369726120294.\u001b[0m\n\u001b[32m[I 2021-02-09 13:06:42,335]\u001b[0m Trial 11 finished with value: 0.35849222518370827 and parameters: {'num_topics': 10, 'alpha': 0.31, 'eta': 'symmetric', 'chunksize': 1000, 'passes': 9, 'iterations': 150}. Best is trial 3 with value: 0.39528369726120294.\u001b[0m\n\u001b[32m[I 2021-02-09 13:07:07,459]\u001b[0m Trial 12 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 13:07:26,511]\u001b[0m Trial 13 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 13:07:48,852]\u001b[0m Trial 14 pruned. \u001b[0m\n"
    }
   ],
   "source": [
    "import logging\n",
    "import re\n",
    "import ntpath\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.handlers.RotatingFileHandler(\"optuna.log\",maxBytes=100000,backupCount=3))\n",
    "\n",
    "study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(3)\n",
    "# use the input file name as the study name\n",
    "study_name = re.sub(r'[.]\\w+','', ntpath.basename(data_filename)) + \"-study\"\n",
    "print(study_name)\n",
    "storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=100, callbacks=[study_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Study statistics: \n  Number of finished trials:  8\n  Number of pruned trials:  3\n  Number of complete trials:  5\nBest trial:\n  Value:  0.39528369726120294\n  Params: \n    alpha: 0.9099999999999999\n    chunksize: 500\n    eta: 0.31\n    iterations: 100\n    num_topics: 8\n    passes: 5\nOrderedDict([('eta', 0.5372835880569031), ('num_topics', 0.2045973515629733), ('chunksize', 0.09080709850001285), ('alpha', 0.06545222829713203), ('passes', 0.06402147359473), ('iterations', 0.03783825998824882)])\n"
    }
   ],
   "source": [
    "# print(study.best_params)\n",
    "# print(study.best_value)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(optuna.importance.get_param_importances(study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1612893566040",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}