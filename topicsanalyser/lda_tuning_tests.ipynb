{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = TopicsFinder(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha = [0.01]\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta = [0.01]\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "corpus = finder.corpus\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    # cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                    #                               k=k, a=a, b=b)\n",
    "                    mod, cv = finder.fit_LDA_model(\n",
    "                        random_state=100,\n",
    "                        chunksize=chunksize,\n",
    "                        passes=passes,\n",
    "                        iterations=iterations,\n",
    "                        eval_every=eval_every,\n",
    "                        num_topics = k,\n",
    "                        alpha = a,\n",
    "                        eta = b,\n",
    "\n",
    "                    )\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv.get_coherence())\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader\n",
    "import optuna\n",
    "\n",
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "# reader = TextFileReader('./sample_data/data.xlsx')\n",
    "# data = reader.get_dataframe('Please briefly describe an example of one burdensome administrative task or process which you believe is \"low value\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    k = trial.suggest_int('num_topics', 1, 10)\n",
    "    a = trial.suggest_discrete_uniform('alpha', 0.01, 1, 0.3)\n",
    "    b = trial.suggest_discrete_uniform('eta', 0.01, 1, 0.3)\n",
    "    chunksize = 2000\n",
    "    passes = 20\n",
    "    iterations = 400\n",
    "    eval_every = None  \n",
    "\n",
    "    finder = TopicsFinder(data)\n",
    "    _, cv = finder.fit_LDA_model(\n",
    "        random_state=100,\n",
    "        chunksize=chunksize,\n",
    "        passes=passes,\n",
    "        iterations=iterations,\n",
    "        eval_every=eval_every,\n",
    "        num_topics = k,\n",
    "        alpha = a,\n",
    "        eta = b,\n",
    "    )\n",
    "    return cv.get_coherence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\u001b[32m[I 2021-02-05 13:01:37,701]\u001b[0m A new study created in memory with name: no-name-543508f9-06a8-4eae-b18b-183133bf4307\u001b[0m\n\u001b[32m[I 2021-02-05 13:02:17,012]\u001b[0m Trial 0 finished with value: 0.20094865437364023 and parameters: {'num_topics': 2, 'alpha': 0.31, 'eta': 0.9099999999999999}. Best is trial 0 with value: 0.20094865437364023.\u001b[0m\n\u001b[32m[I 2021-02-05 13:02:53,290]\u001b[0m Trial 1 finished with value: 0.37583864706464165 and parameters: {'num_topics': 10, 'alpha': 0.31, 'eta': 0.61}. Best is trial 1 with value: 0.37583864706464165.\u001b[0m\n\u001b[32m[I 2021-02-05 13:03:22,489]\u001b[0m Trial 2 finished with value: 0.3362049638266521 and parameters: {'num_topics': 8, 'alpha': 0.9099999999999999, 'eta': 0.01}. Best is trial 1 with value: 0.37583864706464165.\u001b[0m\n\u001b[32m[I 2021-02-05 13:03:52,108]\u001b[0m Trial 3 finished with value: 0.2291558306618219 and parameters: {'num_topics': 2, 'alpha': 0.9099999999999999, 'eta': 0.01}. Best is trial 1 with value: 0.37583864706464165.\u001b[0m\n\u001b[32m[I 2021-02-05 13:04:21,282]\u001b[0m Trial 4 finished with value: 0.35707548443040954 and parameters: {'num_topics': 8, 'alpha': 0.61, 'eta': 0.01}. Best is trial 1 with value: 0.37583864706464165.\u001b[0m\n\u001b[32m[I 2021-02-05 13:04:57,227]\u001b[0m Trial 5 finished with value: 0.30361302002742707 and parameters: {'num_topics': 4, 'alpha': 0.01, 'eta': 0.31}. Best is trial 1 with value: 0.37583864706464165.\u001b[0m\n\u001b[32m[I 2021-02-05 13:05:29,629]\u001b[0m Trial 6 finished with value: 0.31181803074762593 and parameters: {'num_topics': 7, 'alpha': 0.61, 'eta': 0.61}. Best is trial 1 with value: 0.37583864706464165.\u001b[0m\n\u001b[32m[I 2021-02-05 13:06:06,792]\u001b[0m Trial 7 finished with value: 0.43024990567547255 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999}. Best is trial 7 with value: 0.43024990567547255.\u001b[0m\n\u001b[32m[I 2021-02-05 13:06:42,901]\u001b[0m Trial 8 finished with value: 0.2952301411306102 and parameters: {'num_topics': 3, 'alpha': 0.01, 'eta': 0.61}. Best is trial 7 with value: 0.43024990567547255.\u001b[0m\n\u001b[32m[I 2021-02-05 13:07:16,417]\u001b[0m Trial 9 finished with value: 0.32830139140129677 and parameters: {'num_topics': 8, 'alpha': 0.31, 'eta': 0.01}. Best is trial 7 with value: 0.43024990567547255.\u001b[0m\n"
    }
   ],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999}\n0.43024990567547255\n"
    }
   ],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1612548023604",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}