{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = TopicsFinder(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha = [0.01]\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta = [0.01]\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "corpus = finder.corpus\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    # cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                    #                               k=k, a=a, b=b)\n",
    "                    mod, cv = finder.fit_LDA_model(\n",
    "                        random_state=100,\n",
    "                        chunksize=chunksize,\n",
    "                        passes=passes,\n",
    "                        iterations=iterations,\n",
    "                        eval_every=eval_every,\n",
    "                        num_topics = k,\n",
    "                        alpha = a,\n",
    "                        eta = b,\n",
    "\n",
    "                    )\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv.get_coherence())\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/kapangyu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "# reader = TextFileReader('./sample_data/data.xlsx')\n",
    "# data = reader.get_dataframe('Please briefly describe an example of one burdensome administrative task or process which you believe is \"low value\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWhenTrialKeepBeingPrunedCallback:\n",
    "    def __init__(self, threshold: int):\n",
    "        self.threshold = threshold\n",
    "        self._consequtive_pruned_count = 0\n",
    "\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        if trial.state == optuna.trial.TrialState.PRUNED:\n",
    "            self._consequtive_pruned_count += 1\n",
    "        else:\n",
    "            self._consequtive_pruned_count = 0\n",
    "\n",
    "        if self._consequtive_pruned_count >= self.threshold:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    k = trial.suggest_int('num_topics', 1, 10)\n",
    "    a = trial.suggest_categorical('alpha', list(np.arange(0.01, 1, 0.3)) + ['symmetric','asymmetric'])\n",
    "    b = trial.suggest_categorical('eta', list(np.arange(0.01, 1, 0.3)) + ['symmetric'])\n",
    "    # a = 'auto'\n",
    "    # b = 'auto'\n",
    "    chunksize = trial.suggest_int('chunksize', 100, 2000, step=100)\n",
    "    passes = trial.suggest_int('passes', 1, 10, step=2)\n",
    "    iterations = trial.suggest_int('iterations', 50, 500, step=50)\n",
    "    eval_every = None  \n",
    "\n",
    "    finder = TopicsFinder(data)\n",
    "    _, cv = finder.fit_LDA_model(\n",
    "        random_state=100,\n",
    "        chunksize=chunksize,\n",
    "        passes=passes,\n",
    "        iterations=iterations,\n",
    "        eval_every=eval_every,\n",
    "        num_topics = k,\n",
    "        alpha = a,\n",
    "        eta = b,\n",
    "    )\n",
    "    score = cv.get_coherence()\n",
    "\n",
    "    trial.report(score, 0)\n",
    "    # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\u001b[32m[I 2021-02-09 10:00:55,643]\u001b[0m A new study created in RDB with name: topicsanalyser-study\u001b[0m\n\u001b[32m[I 2021-02-09 10:01:21,080]\u001b[0m Trial 0 finished with value: 0.3864179810644952 and parameters: {'num_topics': 8, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 1200, 'passes': 7, 'iterations': 350}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:01:40,493]\u001b[0m Trial 1 finished with value: 0.3044410561921815 and parameters: {'num_topics': 5, 'alpha': 0.01, 'eta': 0.61, 'chunksize': 1200, 'passes': 3, 'iterations': 100}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:02:03,551]\u001b[0m Trial 2 finished with value: 0.2885890052312071 and parameters: {'num_topics': 5, 'alpha': 0.9099999999999999, 'eta': 0.61, 'chunksize': 1300, 'passes': 7, 'iterations': 150}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:02:30,064]\u001b[0m Trial 3 finished with value: 0.2911753173800437 and parameters: {'num_topics': 3, 'alpha': 0.31, 'eta': 0.01, 'chunksize': 1500, 'passes': 9, 'iterations': 150}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:02:49,990]\u001b[0m Trial 4 finished with value: 0.11116728720081073 and parameters: {'num_topics': 1, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 500, 'passes': 9, 'iterations': 250}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:03:13,050]\u001b[0m Trial 5 finished with value: 0.31078396079330906 and parameters: {'num_topics': 4, 'alpha': 0.61, 'eta': 0.31, 'chunksize': 400, 'passes': 9, 'iterations': 150}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:03:30,313]\u001b[0m Trial 6 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:03:48,322]\u001b[0m Trial 7 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:04:08,602]\u001b[0m Trial 8 finished with value: 0.3052544139182402 and parameters: {'num_topics': 10, 'alpha': 'symmetric', 'eta': 0.01, 'chunksize': 1600, 'passes': 3, 'iterations': 250}. Best is trial 0 with value: 0.3864179810644952.\u001b[0m\n\u001b[32m[I 2021-02-09 10:04:27,758]\u001b[0m Trial 9 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:04:52,311]\u001b[0m Trial 10 finished with value: 0.3965039449123142 and parameters: {'num_topics': 8, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 5, 'iterations': 450}. Best is trial 10 with value: 0.3965039449123142.\u001b[0m\n\u001b[32m[I 2021-02-09 10:05:14,962]\u001b[0m Trial 11 finished with value: 0.3965039449123142 and parameters: {'num_topics': 8, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 5, 'iterations': 450}. Best is trial 10 with value: 0.3965039449123142.\u001b[0m\n\u001b[32m[I 2021-02-09 10:05:37,670]\u001b[0m Trial 12 finished with value: 0.3965039449123142 and parameters: {'num_topics': 8, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 5, 'iterations': 500}. Best is trial 10 with value: 0.3965039449123142.\u001b[0m\n\u001b[32m[I 2021-02-09 10:06:00,971]\u001b[0m Trial 13 finished with value: 0.3888227556684491 and parameters: {'num_topics': 8, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 900, 'passes': 5, 'iterations': 400}. Best is trial 10 with value: 0.3965039449123142.\u001b[0m\n\u001b[32m[I 2021-02-09 10:06:22,644]\u001b[0m Trial 14 finished with value: 0.3507952822123453 and parameters: {'num_topics': 7, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 600, 'passes': 5, 'iterations': 450}. Best is trial 10 with value: 0.3965039449123142.\u001b[0m\n\u001b[32m[I 2021-02-09 10:06:38,576]\u001b[0m Trial 15 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:06:58,249]\u001b[0m Trial 16 finished with value: 0.41657045755663497 and parameters: {'num_topics': 9, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 3, 'iterations': 450}. Best is trial 16 with value: 0.41657045755663497.\u001b[0m\n\u001b[32m[I 2021-02-09 10:07:16,580]\u001b[0m Trial 17 finished with value: 0.3592271898640452 and parameters: {'num_topics': 10, 'alpha': 'asymmetric', 'eta': 'symmetric', 'chunksize': 1000, 'passes': 3, 'iterations': 500}. Best is trial 16 with value: 0.41657045755663497.\u001b[0m\n\u001b[32m[I 2021-02-09 10:07:33,082]\u001b[0m Trial 18 finished with value: 0.367949181230148 and parameters: {'num_topics': 9, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 700, 'passes': 1, 'iterations': 500}. Best is trial 16 with value: 0.41657045755663497.\u001b[0m\n\u001b[32m[I 2021-02-09 10:07:51,931]\u001b[0m Trial 19 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:08:16,896]\u001b[0m Trial 20 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:08:39,024]\u001b[0m Trial 21 finished with value: 0.4249381245725021 and parameters: {'num_topics': 9, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 900, 'passes': 5, 'iterations': 450}. Best is trial 21 with value: 0.4249381245725021.\u001b[0m\n\u001b[32m[I 2021-02-09 10:09:02,419]\u001b[0m Trial 22 finished with value: 0.40723674154310524 and parameters: {'num_topics': 9, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 1100, 'passes': 5, 'iterations': 500}. Best is trial 21 with value: 0.4249381245725021.\u001b[0m\n\u001b[32m[I 2021-02-09 10:09:22,071]\u001b[0m Trial 23 finished with value: 0.38909024797586605 and parameters: {'num_topics': 9, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 1100, 'passes': 3, 'iterations': 450}. Best is trial 21 with value: 0.4249381245725021.\u001b[0m\n\u001b[32m[I 2021-02-09 10:09:45,001]\u001b[0m Trial 24 finished with value: 0.4362987600878685 and parameters: {'num_topics': 10, 'alpha': 0.31, 'eta': 0.9099999999999999, 'chunksize': 1000, 'passes': 5, 'iterations': 350}. Best is trial 24 with value: 0.4362987600878685.\u001b[0m\n\u001b[32m[I 2021-02-09 10:10:09,192]\u001b[0m Trial 25 finished with value: 0.3914616571551982 and parameters: {'num_topics': 10, 'alpha': 0.31, 'eta': 'symmetric', 'chunksize': 600, 'passes': 7, 'iterations': 350}. Best is trial 24 with value: 0.4362987600878685.\u001b[0m\n\u001b[32m[I 2021-02-09 10:10:28,449]\u001b[0m Trial 26 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:10:50,239]\u001b[0m Trial 27 finished with value: 0.4294871795190215 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 900, 'passes': 5, 'iterations': 300}. Best is trial 24 with value: 0.4362987600878685.\u001b[0m\n\u001b[32m[I 2021-02-09 10:11:12,288]\u001b[0m Trial 28 finished with value: 0.41269598398430246 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 1000, 'passes': 5, 'iterations': 300}. Best is trial 24 with value: 0.4362987600878685.\u001b[0m\n\u001b[32m[I 2021-02-09 10:11:36,704]\u001b[0m Trial 29 finished with value: 0.4126909615062483 and parameters: {'num_topics': 10, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 1200, 'passes': 7, 'iterations': 350}. Best is trial 24 with value: 0.4362987600878685.\u001b[0m\n\u001b[32m[I 2021-02-09 10:12:00,982]\u001b[0m Trial 30 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:12:21,542]\u001b[0m Trial 31 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:12:43,540]\u001b[0m Trial 32 finished with value: 0.39218348213665266 and parameters: {'num_topics': 9, 'alpha': 0.01, 'eta': 0.9099999999999999, 'chunksize': 1300, 'passes': 5, 'iterations': 200}. Best is trial 24 with value: 0.4362987600878685.\u001b[0m\n\u001b[32m[I 2021-02-09 10:13:02,290]\u001b[0m Trial 33 finished with value: 0.48458337778563054 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 900, 'passes': 3, 'iterations': 350}. Best is trial 33 with value: 0.48458337778563054.\u001b[0m\n\u001b[32m[I 2021-02-09 10:13:23,212]\u001b[0m Trial 34 finished with value: 0.47745255378104223 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 1200, 'passes': 5, 'iterations': 350}. Best is trial 33 with value: 0.48458337778563054.\u001b[0m\n\u001b[32m[I 2021-02-09 10:13:41,833]\u001b[0m Trial 35 finished with value: 0.41065397815316956 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 1200, 'passes': 3, 'iterations': 350}. Best is trial 33 with value: 0.48458337778563054.\u001b[0m\n\u001b[32m[I 2021-02-09 10:14:03,439]\u001b[0m Trial 36 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:14:26,302]\u001b[0m Trial 37 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 10:14:45,207]\u001b[0m Trial 38 pruned. \u001b[0m\n"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.handlers.RotatingFileHandler(\"optuna.log\",maxBytes=100000,backupCount=3))\n",
    "\n",
    "study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(3)\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study_name = \"topicsanalyser-study\"\n",
    "storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=100, callbacks=[study_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Study statistics: \n  Number of finished trials:  39\n  Number of pruned trials:  12\n  Number of complete trials:  27\nBest trial:\n  Value:  0.48458337778563054\n  Params: \n    alpha: asymmetric\n    chunksize: 900\n    eta: 0.61\n    iterations: 350\n    num_topics: 8\n    passes: 3\nOrderedDict([('num_topics', 0.5260236281253498), ('iterations', 0.2480903186728618), ('eta', 0.09051292183973614), ('chunksize', 0.07207900047780061), ('alpha', 0.06121455239947173), ('passes', 0.002079578484779893)])\n"
    }
   ],
   "source": [
    "# print(study.best_params)\n",
    "# print(study.best_value)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(optuna.importance.get_param_importances(study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1612880309725",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}