{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = TextFileReader('./sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx')\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = TopicsFinder(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha = [0.01]\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta = [0.01]\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "corpus = finder.corpus\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    # cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                    #                               k=k, a=a, b=b)\n",
    "                    mod, cv = finder.fit_LDA_model(\n",
    "                        random_state=100,\n",
    "                        chunksize=chunksize,\n",
    "                        passes=passes,\n",
    "                        iterations=iterations,\n",
    "                        eval_every=eval_every,\n",
    "                        num_topics = k,\n",
    "                        alpha = a,\n",
    "                        eta = b,\n",
    "\n",
    "                    )\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv.get_coherence())\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicsfinder import TopicsFinder\n",
    "from textfilereader import TextFileReader\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "data_filename = './sample_data/CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1.xlsx'\n",
    "reader = TextFileReader(data_filename)\n",
    "data = reader.get_dataframe('Reason for filling position(s) with Federal Government Employee -OTHER')\n",
    "# reader = TextFileReader('./sample_data/data.xlsx')\n",
    "# data = reader.get_dataframe('Please briefly describe an example of one burdensome administrative task or process which you believe is \"low value\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWhenTrialKeepBeingPrunedCallback:\n",
    "    def __init__(self, threshold: int):\n",
    "        self.threshold = threshold\n",
    "        self._consequtive_pruned_count = 0\n",
    "\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        if trial.state == optuna.trial.TrialState.PRUNED:\n",
    "            self._consequtive_pruned_count += 1\n",
    "        else:\n",
    "            self._consequtive_pruned_count = 0\n",
    "\n",
    "        if self._consequtive_pruned_count >= self.threshold:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    k = trial.suggest_int('num_topics', 1, 10)\n",
    "    a = trial.suggest_categorical('alpha', list(np.arange(0.01, 1, 0.3)) + ['symmetric','asymmetric'])\n",
    "    b = trial.suggest_categorical('eta', list(np.arange(0.01, 1, 0.3)) + ['symmetric'])\n",
    "    # a = 'auto'\n",
    "    # b = 'auto'\n",
    "    chunksize = trial.suggest_int('chunksize', 100, 2000, step=100)\n",
    "    passes = trial.suggest_int('passes', 1, 10, step=2)\n",
    "    iterations = trial.suggest_int('iterations', 50, 500, step=50)\n",
    "    eval_every = None  \n",
    "\n",
    "    finder = TopicsFinder(data)\n",
    "    _, cv = finder.fit_LDA_model(\n",
    "        random_state=100,\n",
    "        chunksize=chunksize,\n",
    "        passes=passes,\n",
    "        iterations=iterations,\n",
    "        eval_every=eval_every,\n",
    "        num_topics = k,\n",
    "        alpha = a,\n",
    "        eta = b,\n",
    "    )\n",
    "    score = cv.get_coherence()\n",
    "\n",
    "    trial.report(score, 0)\n",
    "    # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\u001b[32m[I 2021-02-09 11:59:37,573]\u001b[0m Using an existing study with name 'CSS_Hiring_Data_FedEmployee_Reason_OTHER_v1-study' instead of creating a new one.\u001b[0m\nCSS_Hiring_Data_FedEmployee_Reason_OTHER_v1-study\n\u001b[32m[I 2021-02-09 12:00:03,189]\u001b[0m Trial 4 finished with value: 0.2727888100277903 and parameters: {'num_topics': 3, 'alpha': 'symmetric', 'eta': 0.01, 'chunksize': 1600, 'passes': 9, 'iterations': 500}. Best is trial 0 with value: 0.34936863299950116.\u001b[0m\n\u001b[32m[I 2021-02-09 12:00:18,300]\u001b[0m Trial 5 finished with value: 0.24337224084590942 and parameters: {'num_topics': 9, 'alpha': 0.9099999999999999, 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 1, 'iterations': 250}. Best is trial 0 with value: 0.34936863299950116.\u001b[0m\n\u001b[32m[I 2021-02-09 12:00:44,177]\u001b[0m Trial 6 finished with value: 0.3273465889649688 and parameters: {'num_topics': 5, 'alpha': 0.01, 'eta': 0.61, 'chunksize': 1800, 'passes': 9, 'iterations': 150}. Best is trial 0 with value: 0.34936863299950116.\u001b[0m\n\u001b[32m[I 2021-02-09 12:01:04,285]\u001b[0m Trial 7 finished with value: 0.33213144294650276 and parameters: {'num_topics': 6, 'alpha': 0.61, 'eta': 0.61, 'chunksize': 500, 'passes': 5, 'iterations': 350}. Best is trial 0 with value: 0.34936863299950116.\u001b[0m\n\u001b[32m[I 2021-02-09 12:01:23,507]\u001b[0m Trial 8 finished with value: 0.3073674067417217 and parameters: {'num_topics': 7, 'alpha': 0.61, 'eta': 0.01, 'chunksize': 1000, 'passes': 5, 'iterations': 350}. Best is trial 0 with value: 0.34936863299950116.\u001b[0m\n\u001b[32m[I 2021-02-09 12:01:43,911]\u001b[0m Trial 9 finished with value: 0.4473996584370433 and parameters: {'num_topics': 9, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 1700, 'passes': 3, 'iterations': 400}. Best is trial 9 with value: 0.4473996584370433.\u001b[0m\n\u001b[32m[I 2021-02-09 12:02:03,998]\u001b[0m Trial 10 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 12:02:20,271]\u001b[0m Trial 11 finished with value: 0.4468212003618338 and parameters: {'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 200, 'passes': 1, 'iterations': 50}. Best is trial 9 with value: 0.4473996584370433.\u001b[0m\n\u001b[32m[I 2021-02-09 12:02:37,581]\u001b[0m Trial 12 finished with value: 0.4370327645320497 and parameters: {'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 100, 'passes': 1, 'iterations': 50}. Best is trial 9 with value: 0.4473996584370433.\u001b[0m\n\u001b[32m[I 2021-02-09 12:02:56,345]\u001b[0m Trial 13 finished with value: 0.4137957748637434 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 100, 'passes': 3, 'iterations': 50}. Best is trial 9 with value: 0.4473996584370433.\u001b[0m\n\u001b[32m[I 2021-02-09 12:03:16,655]\u001b[0m Trial 14 finished with value: 0.3942011491771075 and parameters: {'num_topics': 10, 'alpha': 0.31, 'eta': 0.61, 'chunksize': 1300, 'passes': 3, 'iterations': 400}. Best is trial 9 with value: 0.4473996584370433.\u001b[0m\n\u001b[32m[I 2021-02-09 12:03:31,826]\u001b[0m Trial 15 finished with value: 0.4626517308187343 and parameters: {'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.61, 'chunksize': 600, 'passes': 1, 'iterations': 150}. Best is trial 15 with value: 0.4626517308187343.\u001b[0m\n\u001b[32m[I 2021-02-09 12:03:49,567]\u001b[0m Trial 16 finished with value: 0.5030009001346393 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 600, 'passes': 3, 'iterations': 150}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:04:10,544]\u001b[0m Trial 17 finished with value: 0.4790789501696335 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 500, 'passes': 7, 'iterations': 150}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:04:32,893]\u001b[0m Trial 18 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 12:04:55,063]\u001b[0m Trial 19 finished with value: 0.4138738521819963 and parameters: {'num_topics': 7, 'alpha': 'symmetric', 'eta': 0.9099999999999999, 'chunksize': 700, 'passes': 7, 'iterations': 100}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:05:16,552]\u001b[0m Trial 20 finished with value: 0.4650025580199157 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 300, 'passes': 7, 'iterations': 200}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:05:38,767]\u001b[0m Trial 21 finished with value: 0.44332688254538 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 1300, 'passes': 7, 'iterations': 100}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:06:00,205]\u001b[0m Trial 22 finished with value: 0.4650025580199157 and parameters: {'num_topics': 7, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 300, 'passes': 7, 'iterations': 200}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:06:22,051]\u001b[0m Trial 23 finished with value: 0.5000772047700399 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 7, 'iterations': 200}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:06:43,977]\u001b[0m Trial 24 finished with value: 0.5000772047700399 and parameters: {'num_topics': 8, 'alpha': 'asymmetric', 'eta': 0.9099999999999999, 'chunksize': 800, 'passes': 7, 'iterations': 200}. Best is trial 16 with value: 0.5030009001346393.\u001b[0m\n\u001b[32m[I 2021-02-09 12:07:06,896]\u001b[0m Trial 25 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 12:07:26,874]\u001b[0m Trial 26 pruned. \u001b[0m\n\u001b[32m[I 2021-02-09 12:07:44,693]\u001b[0m Trial 27 pruned. \u001b[0m\n"
    }
   ],
   "source": [
    "import logging\n",
    "import ntpath\n",
    "import re\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.handlers.RotatingFileHandler(\"optuna.log\",maxBytes=100000,backupCount=3))\n",
    "\n",
    "study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(3)\n",
    "# use the input file name as the study name\n",
    "study_name = re.sub(r'[.]\\w+','', ntpath.basename(data_filename)) + \"-study\"\n",
    "print(study_name)\n",
    "storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=100, callbacks=[study_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Study statistics: \n  Number of finished trials:  28\n  Number of pruned trials:  5\n  Number of complete trials:  22\nBest trial:\n  Value:  0.5030009001346393\n  Params: \n    alpha: asymmetric\n    chunksize: 600\n    eta: 0.9099999999999999\n    iterations: 150\n    num_topics: 8\n    passes: 3\nOrderedDict([('alpha', 0.7631449798592982), ('iterations', 0.09925148985412988), ('num_topics', 0.0657961022883631), ('eta', 0.0439507006900773), ('chunksize', 0.023796515802302784), ('passes', 0.004060211505828795)])\n"
    }
   ],
   "source": [
    "# print(study.best_params)\n",
    "# print(study.best_value)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial2:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(optuna.importance.get_param_importances(study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1612888791321",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}